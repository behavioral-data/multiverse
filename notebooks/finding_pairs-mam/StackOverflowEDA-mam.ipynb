{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "# from dask.dot import dot_graph\n",
    "import re\n",
    "from dask.diagnostics import ProgressBar\n",
    "import html\n",
    "\n",
    "import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster,threads_per_worker = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:29269\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>96</li>\n",
       "  <li><b>Memory: </b>3.25 TB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:29269' processes=12 cores=96>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_column_value(line, col_name, cast_type=str):\n",
    "    pattern_tpl = r'{col}=\"([^\"]*)\"'\n",
    "    pattern = pattern_tpl.format(col=col_name)\n",
    "    match = re.search(pattern, line)\n",
    "\n",
    "    if cast_type == int:\n",
    "        null_value = 0\n",
    "    else:\n",
    "        null_value = None\n",
    "\n",
    "    return cast_type(match[1]) if match is not None else null_value\n",
    "\n",
    "\n",
    "def extract_comments_columns(line):\n",
    "    text = extract_column_value(line, 'Text', str)\n",
    "    row = {\n",
    "        'id': extract_column_value(line, 'Id', int),\n",
    "        'post_id':extract_column_value(line, 'PostId', str),\n",
    "        'text': text ,\n",
    "        'code_snippets': extract_code(text)\n",
    "    }\n",
    "    return row\n",
    "\n",
    "def explode(df,col):\n",
    "    return df.explode(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(text):\n",
    "    CODE_SNIPPETS_REGEX = r\"(?<=<code>)(.*?)(?=<\\/code>)\"\n",
    "    return re.findall(CODE_SNIPPETS_REGEX,text)\n",
    "\n",
    "def extract_posts_columns(line):\n",
    "    body = html.unescape(extract_column_value(line, 'Body', str))\n",
    "    row = {\n",
    "        'id': extract_column_value(line, 'Id', int),\n",
    "        'post_type': extract_column_value(line, \"PostTypeId\", int),\n",
    "        'parent_id' : extract_column_value(line, \"ParentId\", int),\n",
    "        'answer_count': extract_column_value(line, 'AnswerCount', int),\n",
    "        'tags': extract_column_value(line, 'Tags', str),\n",
    "        'body': body,\n",
    "        'code_snippets': extract_code(body)\n",
    "    }\n",
    "    return row\n",
    "\n",
    "\n",
    "def is_fruitful_question(line):\n",
    "    return (line.get(\"post_type\") == 1) and  (line.get(\"answer_count\") > 0) \n",
    "\n",
    "def is_response(line):\n",
    "    return line.get(\"post_type\") == 2\n",
    "\n",
    "def is_python(line):\n",
    "    return \"python\" in line[\"tags\"]\n",
    "\n",
    "def filter_post_line(line):\n",
    "    return is_fruitful_question(line) or is_response(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44834 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44836 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44838 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44900 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44902 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44904 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44906 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44908 remote=tcp://127.0.0.1:29269>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44910 remote=tcp://127.0.0.1:29269>\n"
     ]
    }
   ],
   "source": [
    "posts = db.read_text('/projects/bdata/stackoverflow/stackoverflow/Posts.xml', encoding = 'utf-8',\n",
    "                           blocksize=10000000)\\\n",
    "                        .filter(lambda line: line.find('<row') >= 0)\\\n",
    "                        .map(extract_posts_columns)\\\n",
    "                        .filter(filter_post_line)\\\n",
    "                        .to_dataframe()\\\n",
    "                        .map_partitions(lambda x: explode(x,\"code_snippets\"))\\\n",
    "                        .compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_questions = posts[(posts[\"post_type\"] == 1) & (posts[\"tags\"].str.contains(\"python\"))][\"id\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_posts = posts.merge(python_questions , how=\"right\", \n",
    "                           left_on = (posts[\"post_type\"] == 1)*(posts[\"id\"]) + (posts[\"post_type\"] != 1)*(posts[\"parent_id\"]),\n",
    "                           right_on = \"id\")\n",
    "python_posts[\"question_key\"] = (python_posts[\"post_type\"] == 1)*(python_posts[\"id\"]) + \\\n",
    "                               (python_posts[\"post_type\"] != 1)*(python_posts[\"parent_id\"])\n",
    "\n",
    "python_posts = python_posts[[\"question_key\",\"id\",\"answer_count\",\"body\",\"code_snippets\"]]\n",
    "python_posts = python_posts.dropna(subset = [\"code_snippets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't just want to do the edit distance like we had with Kaggle. Maybe there's something more interesting we can do with co-occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code_snippet(code):\n",
    "    try:\n",
    "        no_chars = re.sub('[^a-zA-Z\\n]+', ' ', code)\n",
    "    except TypeError:\n",
    "        print(code)\n",
    "    tokens = split_func_name(no_chars)\n",
    "    return tokens\n",
    "    \n",
    "def split_func_name(func):\n",
    "    \"\"\"\n",
    "    split function names\n",
    "    eg. sklearn.metrics.pairwise.cosine_similarity -> [sklearn, metrics, pairwise, cosine, similarity]\n",
    "    \"\"\"\n",
    "    new_str = ''\n",
    "    for i, l in enumerate(func):\n",
    "#         if i > 0 and l.isupper() and func[i - 1].islower():\n",
    "#             new_str += '.'\n",
    "        if i > 0 and i < len(func) - 1 and l.isupper() and func[i - 1].isupper() and func[i + 1].islower():\n",
    "            new_str += '.'\n",
    "        elif i > 0 and l.isdigit() and func[i - 1].isalpha():\n",
    "            new_str += '.'\n",
    "        elif i < len(func) - 1 and l.isalpha() and func[i - 1].isdigit():\n",
    "            new_str += '.'\n",
    "        else:\n",
    "            pass\n",
    "        new_str += l\n",
    "    return re.split('\\.|_|\\s', new_str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sklearn', 'onehotencoder']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_func_name(\"sklearn.OneHotEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccurence(X,max_features = int(1e4),diag_norm = False):\n",
    "    vectorizer = CountVectorizer(max_features=max_features, tokenizer=tokenize_code_snippet)\n",
    "    vectors = (vectorizer.fit_transform(X) > 0).astype(int)\n",
    "    res = np.dot(vectors.T,vectors)\n",
    "    if diag_norm:\n",
    "        g = sp.diags(1./res.diagonal())\n",
    "        res = g * res\n",
    "    return res, vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_code = python_posts.groupby(\"question_key\")['code_snippets'].transform(' '.join).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_code_cooccurence = cooccurence(question_code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_cooccurences(token,matrix,vocab,top_n = 5):\n",
    "    query_index = vocab.get(token)\n",
    "    if query_index is None:\n",
    "        raise KeyError(\"Not in Vocab\")\n",
    "    else:\n",
    "        reverse_index = {v: k for k, v in vocab.items()}\n",
    "        row = matrix[query_index].toarray().flatten()\n",
    "        top_occ = (-row).argsort()[:top_n]\n",
    "        \n",
    "        keys = [reverse_index.get(x) for x in top_occ ] \n",
    "        counts = row[top_occ]\n",
    "        print(counts)\n",
    "        print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158  48  45  44  36]\n",
      "['onehotencoder', 'labelencoder', 'sklearn', '', 'dummies']\n"
     ]
    }
   ],
   "source": [
    "display_top_cooccurences(\"onehotencoder\",*so_code_cooccurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140  52  52  49  37  28  26  24  20  19  17  16  16  16  14  14  13  13\n",
      "  12  12]\n",
      "['cosine', 'distance', 'similarity', '', 'scipy', 'spatial', 'np', 'a', 'x', 'sklearn', 'pairwise', 'metrics', 'matrix', 'b', 'i', 'd', 'n', 'numpy', 'dot', 'y']\n"
     ]
    }
   ],
   "source": [
    "display_top_cooccurences(\"cosine\",*so_code_cooccurence,top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105  43  42  39  28]\n",
      "['ols', 'statsmodels', 'x', 'y', '']\n"
     ]
    }
   ],
   "source": [
    "display_top_cooccurences(\"ols\",*so_code_cooccurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172  67  64  55  35  34  30  27  25  24  18  17  17  15  15  14  14  13\n",
      "  12  12]\n",
      "['svm', '', 'sklearn', 'svc', 'predict', 'x', 'fit', 'y', 'clf', 'train', 'model', 'c', 'kernel', 'linearsvc', 'linear', 'scikit', 'libsvm', 'n', 'python', 'learn']\n"
     ]
    }
   ],
   "source": [
    "display_top_cooccurences(\"svm\",*so_code_cooccurence,top_n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Libraries\n",
    "Which libraries are most commonly referenced on StackOverflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_regex = re.compile(\"^\\s*(?:from|import)\\s+(\\w+(?:\\s*,\\s*\\w+)*)\")\n",
    "top_libraries = python_posts[\"code_snippets\"].str.extract(library_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__future__    1230\n",
       "numpy          752\n",
       "foo            657\n",
       "sys            565\n",
       "django         555\n",
       "module         551\n",
       "os             532\n",
       "tkinter        501\n",
       "matplotlib     383\n",
       "pandas         303\n",
       "datetime       302\n",
       "package        283\n",
       "math           275\n",
       "x              255\n",
       "a              241\n",
       "random         239\n",
       "tensorflow     238\n",
       "app            234\n",
       "time           230\n",
       "re             226\n",
       "pdb            217\n",
       "cv2            216\n",
       "scipy          202\n",
       "Tkinter        174\n",
       "sklearn        171\n",
       "pygame         170\n",
       "PIL            159\n",
       "json           152\n",
       "urllib         150\n",
       "this           148\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_libraries[0].value_counts().sort_values(ascending = False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
