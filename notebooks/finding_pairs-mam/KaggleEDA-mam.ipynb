{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Notebook EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "import scipy\n",
    "import re\n",
    "import difflib\n",
    "from IPython.core.display import display, HTML\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import pickle\n",
    "\n",
    "import ast\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import pybktree\n",
    "import editdistance\n",
    "import tabulate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import astor\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from diff_match_patch import diff_match_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pulled all \"kernels\" related to the IEE Fraud Detection Kaggle competition using `python fetch_kaggle_notebooks.py ieee-fraud-detection ieee-fraud-detection --save_kernel_metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_kernel_json(path,scriptify=True):\n",
    "    with open(path,\"r\") as file:\n",
    "        result = json.loads(file.read())\n",
    "        if result[\"kernelType\"] == \"notebook\":\n",
    "            source =  json.loads(result[\"source\"])\n",
    "            if scriptify:\n",
    "                result[\"source\"] = convert_nb_to_py_script(source) \n",
    "            else:\n",
    "                result[\"source\"] = source\n",
    "        return result\n",
    "  \n",
    "    \n",
    "def comment_cells(cell_source):\n",
    "    if isinstance(cell_source,str):\n",
    "        cell_source = cell_source.split(\"\\n\")\n",
    "    lines = [\"###\"+x for x in cell_source]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def convert_nb_to_py_script(nb_json):\n",
    "    result = []\n",
    "    for cell in nb_json[\"cells\"]:\n",
    "        source = cell[\"source\"]\n",
    "        \n",
    "        if isinstance(source,list):\n",
    "            source = \"\\n\".join(source)\n",
    "        \n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            result.append(source)\n",
    "        else:\n",
    "            result.append(comment_cells(source))\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "KERNEL_DIR = \"/projects/bdata/kaggle/competitions/ieee-fraud-detection/\"\n",
    "kernel_json_paths = glob.glob(os.path.join(KERNEL_DIR,\"*.json\"))\n",
    "kernel_jsons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in kernel_json_paths:\n",
    "    res = load_kaggle_kernel_json(path)\n",
    "    if res:\n",
    "        kernel_jsons.append(res)\n",
    "        \n",
    "kernel_metadata = pd.read_csv(os.path.join(KERNEL_DIR,\"metadata.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Notebooks\n",
    "## Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_distances(kernels,metric):\n",
    "    kernel_source = [x[\"source\"] for x in kernels]\n",
    "    print(\"hey\")\n",
    "    return pairwise_distances(kernel_source,metric)\n",
    "\n",
    "    \n",
    "def minimumEditDistance(s1,s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1\n",
    "    distances = range(len(s1) + 1)\n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1])\n",
    "            else:\n",
    "                newDistances.append(1 + min((distances[index1],\n",
    "                                             distances[index1+1],\n",
    "                                             newDistances[-1])))\n",
    "        distances = newDistances\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is going to take too long :( \n",
    "Try tokenizing using Ge's method and use cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code_snippet(code):\n",
    "    try:\n",
    "        no_chars = re.sub('[^a-zA-Z\\n]+', ' ', code)\n",
    "    except TypeError:\n",
    "        print(code)\n",
    "    tokens = split_func_name(no_chars)\n",
    "    return tokens\n",
    "    \n",
    "def split_func_name(func):\n",
    "    \"\"\"\n",
    "    split function names\n",
    "    eg. sklearn.metrics.pairwise.cosine_similarity -> [sklearn, metrics, pairwise, cosine, similarity]\n",
    "    \"\"\"\n",
    "    new_str = ''\n",
    "    for i, l in enumerate(func):\n",
    "        if i > 0 and l.isupper() and func[i - 1].islower():\n",
    "            new_str += '.'\n",
    "        elif i > 0 and i < len(func) - 1 and l.isupper() and func[i - 1].isupper() and func[i + 1].islower():\n",
    "            new_str += '.'\n",
    "        elif i > 0 and l.isdigit() and func[i - 1].isalpha():\n",
    "            new_str += '.'\n",
    "        elif i < len(func) - 1 and l.isalpha() and func[i - 1].isdigit():\n",
    "            new_str += '.'\n",
    "        else:\n",
    "            pass\n",
    "        new_str += l\n",
    "    return re.split('\\.|_|\\s', new_str.lower())\n",
    "\n",
    "def tokenize_kernels(kernels):\n",
    "    return [tokenize_code_snippet(x[\"source\"]) for x in kernels]\n",
    "\n",
    "kernel_tokens = tokenize_kernels(kernel_jsons)\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "kernel_token_vectors = vectorizer.fit_transform([\" \".join(x) for x in kernel_tokens])\n",
    "normed_kernel_vectors = sklearn.preprocessing.normalize(kernel_token_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/mikeam/anaconda3/envs/analysis/lib/python3.7/site-packages/sklearn/neighbors/_base.py:413: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    }
   ],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(normed_kernel_vectors)\n",
    "nn_distances, nn_indices = nbrs.kneighbors(normed_kernel_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def html_diff(a,b):\n",
    "    differ = difflib.HtmlDiff(wrapcolumn = 80)\n",
    "    return differ.make_table(a.split(\"\\n\"),b.split(\"\\n\"), context = True)\n",
    "\n",
    "def compare_diff(kernels, indices, print_description = True):\n",
    "    orig = kernels[indices[0]]\n",
    "    nn = kernels[indices[1]]\n",
    "    if print_description:\n",
    "        print(\"Left:\",orig[\"author\"], orig[\"slug\"])\n",
    "        print(\"Right:\", nn[\"author\"], nn[\"slug\"])\n",
    "    display(HTML(html_diff(orig[\"source\"],nn[\"source\"])))\n",
    "    \n",
    "def indices_to_author_slug(kernels, indices):\n",
    "    to_return = []\n",
    "    for i in indices:\n",
    "        to_return.append([])\n",
    "        for ii in i:\n",
    "            to_return[-1].append(itemgetter(\"author\",\"slug\")(kernels[ii]))\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the closest notebook usually uploaded by the same user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_names = indices_to_author_slug(kernel_jsons,nn_indices)\n",
    "sum([x[0][0] in  ([x[1][0],x[2][0]]) for x in nn_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to \"align\" these notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about cells?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_jsons = []\n",
    "for path in kernel_json_paths:\n",
    "    res = load_kaggle_kernel_json(path,scriptify=False)\n",
    "    if res:\n",
    "        if res[\"kernelType\"] != \"notebook\":\n",
    "            continue\n",
    "        kernel = []\n",
    "        for cell in res[\"source\"][\"cells\"]:\n",
    "            if type(cell[\"source\"]) is list:\n",
    "                continue\n",
    "            cell_json = copy.deepcopy(cell)\n",
    "            cell_json.update({\"kernel_id\":res[\"id\"]})\n",
    "            cell_jsons.append(cell_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_tokens = tokenize_kernels(cell_jsons)\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "cell_token_vectors = vectorizer.fit_transform([\" \".join(x) for x in cell_tokens])\n",
    "normed_cell_vectors = sklearn.preprocessing.normalize(cell_token_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/mikeam/anaconda3/envs/analysis/lib/python3.7/site-packages/sklearn/neighbors/_base.py:413: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    }
   ],
   "source": [
    "cell_nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(normed_cell_vectors)\n",
    "cell_nn_distances, cell_nn_indices = cell_nbrs.kneighbors(normed_cell_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table class=\"diff\" id=\"difflib_chg_to1__top\"\n",
       "           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        \n",
       "        <tbody>\n",
       "            <tr><td class=\"diff_next\" id=\"difflib_chg_to1__0\"><a href=\"#difflib_chg_to1__top\">t</a></td><td class=\"diff_header\" id=\"from1_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">df_train&nbsp;=&nbsp;comb[:-a]</span></td><td class=\"diff_next\"><a href=\"#difflib_chg_to1__top\">t</a></td><td class=\"diff_header\" id=\"to1_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_add\">df_train&nbsp;=&nbsp;comb[:len(df_train)]</span></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_2\">2</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">df_test&nbsp;=&nbsp;comb[-a:]</span></td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_2\">2</td><td nowrap=\"nowrap\"><span class=\"diff_add\">df_test&nbsp;=&nbsp;comb[len(df_train):]</span></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_3\">3</td><td nowrap=\"nowrap\">del&nbsp;comb</td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_3\">3</td><td nowrap=\"nowrap\">del&nbsp;comb</td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from1_4\">4</td><td nowrap=\"nowrap\">gc.collect()</td><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"to1_4\">4</td><td nowrap=\"nowrap\">gc.collect()</td></tr>\n",
       "        </tbody>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_diff(cell_jsons, cell_nn_indices[500],print_description=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table class=\"diff\" id=\"difflib_chg_to2__top\"\n",
       "           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        \n",
       "        <tbody>\n",
       "            <tr><td class=\"diff_next\" id=\"difflib_chg_to2__0\"><a href=\"#difflib_chg_to2__top\">t</a></td><td class=\"diff_header\" id=\"from2_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">num_preds&nbsp;=&nbsp;5</span></td><td class=\"diff_next\"><a href=\"#difflib_chg_to2__top\">t</a></td><td class=\"diff_header\" id=\"to2_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_add\">from&nbsp;keras.layers&nbsp;import&nbsp;concatenate</span></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_2\">2</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">num_features&nbsp;=&nbsp;test.shape[1]</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_3\">3</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_4\">4</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_5\">5</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">def&nbsp;get_model():</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_6\">6</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;inp&nbsp;=&nbsp;keras.layers.Input((num_features,))</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_7\">7</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Reshape((num_features,1))(inp)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_8\">8</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Conv1D(128,num_preds,&nbsp;activation='elu')(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_9\">9</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.BatchNormalization()(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_10\">10</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Conv1D(24,1,&nbsp;activation='elu')(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_11\">11</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.BatchNormalization()(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_12\">12</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Conv1D(16,1,&nbsp;activation='elu')(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_13\">13</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.BatchNormalization()(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_14\">14</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Conv1D(4,1,&nbsp;activation='elu')(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_15\">15</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.Flatten()(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_16\">16</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;keras.layers.BatchNormalization()(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_17\">17</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;out&nbsp;=&nbsp;keras.layers.Dense(1,&nbsp;activation='sigmoid')(x)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_18\">18</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;keras.Model(inputs=inp,&nbsp;outputs=out)</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "            <tr><td class=\"diff_next\"></td><td class=\"diff_header\" id=\"from2_19\">19</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">&nbsp;</span></td><td class=\"diff_next\"></td><td class=\"diff_header\"></td><td nowrap=\"nowrap\"></td></tr>\n",
       "        </tbody>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_diff(cell_jsons, cell_nn_indices[130],print_description=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about a BK-Tree with Levenshtein distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "editdistance.eval('banana', 'bahama')\n",
    "tree = pybktree.BKTree(editdistance.eval, [x[\"source\"] for x in cell_jsons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_BK_Tree(cells):\n",
    "    cell_sources = [x[\"source\"] for x in cell_jsons]\n",
    "    tree = pybktree.BKTree(editdistance.eval, cell_sources)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matches(source,tree,edit_threshold = 25,limit = 10):\n",
    "    matches = sorted(tree.find(source, edit_threshold))[:limit] \n",
    "#     matches.insert(0,\"\\n\\n\\n\\n\\n\\n\" +  matches[0][1]) \n",
    "#     print(matches)\n",
    "    print(tabulate.tabulate(matches, headers = [\"Edit Distance\",\"Match\"],tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BKTree using eval with 1602 top-level nodes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy.deepcopy(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences are hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│   Edit Distance │ Match                                                                                                                  │\n",
      "╞═════════════════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
      "│               4 │ NFOLDS = 15                                                                                                            │\n",
      "│                 │ folds = KFold(n_splits=NFOLDS)                                                                                         │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ columns = X.columns                                                                                                    │\n",
      "│                 │ splits = folds.split(X, y)                                                                                             │\n",
      "│                 │ y_preds = np.zeros(X_test.shape[0])                                                                                    │\n",
      "│                 │ y_oof = np.zeros(X.shape[0])                                                                                           │\n",
      "│                 │ score = 0                                                                                                              │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ feature_importances = pd.DataFrame()                                                                                   │\n",
      "│                 │ feature_importances['feature'] = columns                                                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ for fold_n, (train_index, valid_index) in enumerate(splits):                                                           │\n",
      "│                 │     X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]                                      │\n",
      "│                 │     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]                                                        │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     dtrain = lgb.Dataset(X_train, label=y_train)                                                                       │\n",
      "│                 │     dvalid = lgb.Dataset(X_valid, label=y_valid)                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     clf = lgb.train(params, dtrain, 20000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500) │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     y_pred_valid = clf.predict(X_valid)                                                                                │\n",
      "│                 │     y_oof[valid_index] = y_pred_valid                                                                                  │\n",
      "│                 │     print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")                                          │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS                                                             │\n",
      "│                 │     y_preds += clf.predict(X_test) / NFOLDS                                                                            │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     del X_train, X_valid, y_train, y_valid                                                                             │\n",
      "│                 │     gc.collect()                                                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ print(f\"\\nMean AUC = {score}\")                                                                                         │\n",
      "│                 │ print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")                                                                 │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│               9 │ %%time                                                                                                                 │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ NFOLDS = 5                                                                                                             │\n",
      "│                 │ folds = KFold(n_splits=NFOLDS)                                                                                         │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ columns = X.columns                                                                                                    │\n",
      "│                 │ splits = folds.split(X, y)                                                                                             │\n",
      "│                 │ y_preds = np.zeros(X_test.shape[0])                                                                                    │\n",
      "│                 │ y_oof = np.zeros(X.shape[0])                                                                                           │\n",
      "│                 │ score = 0                                                                                                              │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ feature_importances = pd.DataFrame()                                                                                   │\n",
      "│                 │ feature_importances['feature'] = columns                                                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ for fold_n, (train_index, valid_index) in enumerate(splits):                                                           │\n",
      "│                 │     X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]                                      │\n",
      "│                 │     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]                                                        │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     dtrain = lgb.Dataset(X_train, label=y_train)                                                                       │\n",
      "│                 │     dvalid = lgb.Dataset(X_valid, label=y_valid)                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500) │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     y_pred_valid = clf.predict(X_valid)                                                                                │\n",
      "│                 │     y_oof[valid_index] = y_pred_valid                                                                                  │\n",
      "│                 │     print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")                                          │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS                                                             │\n",
      "│                 │     y_preds += clf.predict(X_test) / NFOLDS                                                                            │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     del X_train, X_valid, y_train, y_valid                                                                             │\n",
      "│                 │     gc.collect()                                                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ print(f\"\\nMean AUC = {score}\")                                                                                         │\n",
      "│                 │ print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")                                                                 │\n",
      "├─────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│               9 │ %%time                                                                                                                 │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ NFOLDS = 5                                                                                                             │\n",
      "│                 │ folds = KFold(n_splits=NFOLDS)                                                                                         │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ columns = X.columns                                                                                                    │\n",
      "│                 │ splits = folds.split(X, y)                                                                                             │\n",
      "│                 │ y_preds = np.zeros(X_test.shape[0])                                                                                    │\n",
      "│                 │ y_oof = np.zeros(X.shape[0])                                                                                           │\n",
      "│                 │ score = 0                                                                                                              │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ feature_importances = pd.DataFrame()                                                                                   │\n",
      "│                 │ feature_importances['feature'] = columns                                                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ for fold_n, (train_index, valid_index) in enumerate(splits):                                                           │\n",
      "│                 │     X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]                                      │\n",
      "│                 │     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]                                                        │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     dtrain = lgb.Dataset(X_train, label=y_train)                                                                       │\n",
      "│                 │     dvalid = lgb.Dataset(X_valid, label=y_valid)                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500) │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()                                               │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     y_pred_valid = clf.predict(X_valid)                                                                                │\n",
      "│                 │     y_oof[valid_index] = y_pred_valid                                                                                  │\n",
      "│                 │     print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")                                          │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS                                                             │\n",
      "│                 │     y_preds += clf.predict(X_test) / NFOLDS                                                                            │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │     del X_train, X_valid, y_train, y_valid                                                                             │\n",
      "│                 │     gc.collect()                                                                                                       │\n",
      "│                 │                                                                                                                        │\n",
      "│                 │ print(f\"\\nMean AUC = {score}\")                                                                                         │\n",
      "│                 │ print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")                                                                 │\n",
      "╘═════════════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "NFOLDS = 5\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "\n",
    "columns = X.columns\n",
    "splits = folds.split(X, y)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X.shape[0])\n",
    "score = 0\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = columns\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n",
    "    \n",
    "    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n",
    "    \n",
    "    y_pred_valid = clf.predict(X_valid)\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n",
    "    \n",
    "    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n",
    "    y_preds += clf.predict(X_test) / NFOLDS\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "    \n",
    "print(f\"\\nMean AUC = {score}\")\n",
    "print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")\"\"\"\n",
    "display_matches(query_string,tree, limit = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│   Edit Distance │ Match                                                                                                 │\n",
      "╞═════════════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
      "│             265 │ def siev_card_feature(df_train, df_test, col):                                                        │\n",
      "│                 │     valid_card = pd.concat([df_train[[col]], df_test[[col]]])                                         │\n",
      "│                 │     valid_card = valid_card[col].value_counts()                                                       │\n",
      "│                 │     valid_card_std = valid_card.values.std()                                                          │\n",
      "│                 │     invalid_cards = valid_card[valid_card < 2]                                                        │\n",
      "│                 │     print('{0}{1}\\nNumber of Rare card : '.format(col, '*'*10), len(invalid_cards))                   │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     valid_card = valid_card[valid_card >= 2]                                                          │\n",
      "│                 │     valid_card = list(valid_card.index)                                                               │\n",
      "│                 │     print('Number of not intersection in Train : ', len(df_train[~df_train[col].isin(df_test[col])])) │\n",
      "│                 │     print('Nmber of intersection in Train : ', len(df_train[df_train[col].isin(df_test[col])]))       │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     df_train[col] = np.where(df_train[col].isin(df_test[col]), df_train[col], np.nan)                 │\n",
      "│                 │     df_test[col]  = np.where(df_test[col].isin(df_train[col]), df_test[col], np.nan)                  │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     df_train[col] = np.where(df_train[col].isin(valid_card), df_train[col], np.nan)                   │\n",
      "│                 │     df_test[col]  = np.where(df_test[col].isin(valid_card), df_test[col], np.nan)                     │\n",
      "├─────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│             358 │ i_cols = ['card1']                                                                                    │\n",
      "│                 │                                                                                                       │\n",
      "│                 │ for col in i_cols:                                                                                    │\n",
      "│                 │     valid_card = pd.concat([train_df[[col]], test_df[[col]]])                                         │\n",
      "│                 │     valid_card = valid_card[col].value_counts()                                                       │\n",
      "│                 │     valid_card = valid_card[valid_card>2]                                                             │\n",
      "│                 │     valid_card = list(valid_card.index)                                                               │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)                 │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)                  │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)                   │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)                     │\n",
      "├─────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│             380 │ for col in ['card1']:                                                                                 │\n",
      "│                 │     valid_card = pd.concat([train[[col]], test[[col]]])                                               │\n",
      "│                 │     valid_card = valid_card[col].value_counts()                                                       │\n",
      "│                 │     valid_card = valid_card[valid_card>2]                                                             │\n",
      "│                 │     valid_card = list(valid_card.index)                                                               │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train[col] = np.where(train[col].isin(test[col]), train[col], np.nan)                             │\n",
      "│                 │     test[col]  = np.where(test[col].isin(train[col]), test[col], np.nan)                              │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train[col] = np.where(train[col].isin(valid_card), train[col], np.nan)                            │\n",
      "│                 │     test[col]  = np.where(test[col].isin(valid_card), test[col], np.nan)                              │\n",
      "├─────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│             392 │ ########################### Reset values for \"noise\" card1                                            │\n",
      "│                 │ i_cols = ['card1']                                                                                    │\n",
      "│                 │                                                                                                       │\n",
      "│                 │ for col in i_cols:                                                                                    │\n",
      "│                 │     valid_card = pd.concat([train_df[[col]], test_df[[col]]])                                         │\n",
      "│                 │     valid_card = valid_card[col].value_counts()                                                       │\n",
      "│                 │     valid_card = valid_card[valid_card>2]                                                             │\n",
      "│                 │     valid_card = list(valid_card.index)                                                               │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)                 │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)                  │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)                   │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)                     │\n",
      "├─────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│             392 │ ########################### Reset values for \"noise\" card1                                            │\n",
      "│                 │ i_cols = ['card1']                                                                                    │\n",
      "│                 │                                                                                                       │\n",
      "│                 │ for col in i_cols:                                                                                    │\n",
      "│                 │     valid_card = pd.concat([train_df[[col]], test_df[[col]]])                                         │\n",
      "│                 │     valid_card = valid_card[col].value_counts()                                                       │\n",
      "│                 │     valid_card = valid_card[valid_card>2]                                                             │\n",
      "│                 │     valid_card = list(valid_card.index)                                                               │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)                 │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)                  │\n",
      "│                 │                                                                                                       │\n",
      "│                 │     train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)                   │\n",
      "│                 │     test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)                     │\n",
      "╘═════════════════╧═══════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "for col in ['card1']: \n",
    "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    valid_card = valid_card[col].value_counts()\n",
    "    valid_card_std = valid_card.values.std()\n",
    "\n",
    "    invalid_cards = valid_card[valid_card<=2]\n",
    "    print('Rare cards',len(invalid_cards))\n",
    "\n",
    "    valid_card = valid_card[valid_card>2]\n",
    "    valid_card = list(valid_card.index)\n",
    "\n",
    "    print('No intersection in Train', len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "\n",
    "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)\n",
    "    print('#'*20)\"\"\"\n",
    "\n",
    "display_matches(query_string,tree, edit_threshold=400, limit = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example there's a specific parameter that we're interested (`valid valid_card>2`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there's some way to match on graphs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the closest matches for all cells?\n",
    "metric_sources = lambda x,y: editdistance.eval(x[\"source\"],y[\"source\"])\n",
    "cell_tree = pybktree.BKTree(metric_sources, cell_jsons) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do this faster with Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf536b33a834ded8342757a5249330c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b54a715a389f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mall_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_jsons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medit_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mall_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b54a715a389f>\u001b[0m in \u001b[0;36mget_nn\u001b[0;34m(tree, cell, limit, edit_threshold, copy_tree)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy_tree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medit_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analysis/lib/python3.7/site-packages/pybktree.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, item, n)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_candidates_popleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_distance_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0m_found_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e1a924642921>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# What are the closest matches for all cells?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetric_sources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meditdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcell_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpybktree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBKTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_sources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_jsons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_nn(tree,cell,limit = 3, edit_threshold = 0.25, copy_tree=False):\n",
    "    \n",
    "    if edit_threshold < 1:\n",
    "        edit_threshold = len(cell[\"source\"]) / edit_threshold \n",
    "    if copy_tree:\n",
    "        tree = copy.deepcopy(tree)\n",
    "    nn = sorted(tree.find(cell, edit_threshold), key = lambda x: x[0])[:limit]\n",
    "    return nn\n",
    "\n",
    "all_nn = []\n",
    "for cell in tqdm(sample(cell_jsons,2000)):\n",
    "    nn = get_nn(cell_tree, cell, edit_threshold = 0.25)\n",
    "    all_nn.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_nn, open( \"cell_nn.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_sorted = sorted(all_nn,key = lambda x: x[1][0])\n",
    "has_code_and_interesting = list(filter(lambda x: (x[0][1].get(\"cell_type\") == \"code\") and x[1][0] >= 10,nn_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nn_diff(cell_nn):\n",
    "    diff = html_diff(cell_nn[0][1][\"source\"], cell_nn[1][1][\"source\"])\n",
    "    display(HTML(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[71])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(has_code_and_interesting[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_long = list(filter(lambda x: len(x[0][1][\"source\"]) > 300, has_code_and_interesting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nn_diff(is_long[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining Alternatives\n",
    "Use Kaggle Tasks? https://www.kaggle.com/sobhanmoosavi/us-accidents/tasks?taskId=189\n",
    "When is it important to understand the semantics of the code? Meaning in column names?\n",
    "\n",
    "Another example: https://www.kaggle.com/datasnaek/youtube-new/tasks?taskId=258\n",
    "## What might this look like?\n",
    "Maybe it would be easier to define a decision point discretely examples from code\\\n",
    "\n",
    "For each row, what does the action look like?\n",
    "\n",
    "| Stage    | Decision Point        | Original                                                         | Candidate Replacement                                                                                  |   |\n",
    "|----------|-----------------------|------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|---|\n",
    "| Wrangle  | Missing Data          | `df = df.dropna()`                                               | `df = df.interpolate()`                                                                                |   |\n",
    "| Wrangle  | Outliers              | `df = df[df.between(df.quantile(.15), df.quantile(.85))]`        | `df = df[df.between(df.quantile(.05), df.quantile(.95))]`                                               |   |\n",
    "| Wrangle  | Filtering             | `df = df[df[\"completeness\"] >= 0.9]`                             | `df = df[~df.groupby(\"date\")[\"observation\"].isnull().any()]`                                           |   |\n",
    "| Wrangle  | Transform             | `df[\"x\"] = np.log(df[\"x\"])`                                      | `df[\"x\"] = np.log(df[\"x\"] + 1)`                                                                        |   |\n",
    "| Wrangle  | Data Type             | `df[\"likert_response\"] = pd.Categorical(df[\"likert_response\"])`  | `df[\"likert_response\"] = sklearn.preprocessing.OrdinalEncoder().fit_transform(df[\"likert_response\"]))` |   |\n",
    "| Model    | Assumption Violations | `stats.ttest_ind(rvs1, rvs2)`                                    | `stats.mannwhitneyu(rvs1, rvs2)`                                                                       |   |\n",
    "| Model    | Operationalize DV     |                                                                |                                                                                                        |   |\n",
    "| Model    | Operationalize IV     | `model = \"risk ~ age + body_weight\"`                             | `model = \"risk ~ age + body_weight + is_smoker\"`\"                                                      |   |\n",
    "| Model    | Covariates            | `model = \"risk ~ age + body_weight\"`                             | `model = \"risk ~ age + body_weight + age*body_weight\"`\"                                                |   |\n",
    "| Model    | Model                 | `smf.OLS.from_formula(model,data)`                               | `smf.GLM.from_formula(model,data)`                                                                     |   |\n",
    "| Evaluate | Estimation Method     | `RegressionResults(model)`                                       | `RegressionResults(model).get_robust_results()`                                                        |   |\n",
    "| Evaluate | Inference Criteria    | `RegressionResults(model)`                                       | `statsmodels.stats.multitest.multipletests(pvals,0.05)`                                          |   |\n",
    "\n",
    "Could we do a skip-gram on blocks of data science code? Then autocomplete whatever we label as a \"decision point\" in the original source code? Maybe use a loss function that encourages relationships between notebooks with the same (or similar) tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Decision Points\n",
    "If the first goal is to do this for one notebook, then is it enough to say we insert decision points wherever one of the above is used? If not, maybe we could do some kind of weak supervision (like in Coral) to label decision points according to a similar rubric. \n",
    "\n",
    "Maybe take a model like CORAL, add a decoder to it, and formulate the loss to encourage relationships between notebooks that we know to be related (either same competition or same task) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_string(string):\n",
    "    global c, d\n",
    "    tree = ast.parse(string)\n",
    "    \n",
    "    json_tree = []\n",
    "    def gen_identifier(identifier, node_type = 'identifier'):\n",
    "        pos = len(json_tree)\n",
    "        json_node = {}\n",
    "        json_tree.append(json_node)\n",
    "        json_node['type'] = node_type\n",
    "        json_node['value'] = identifier\n",
    "        return pos\n",
    "    \n",
    "    def traverse_list(l, node_type = 'list'):\n",
    "        pos = len(json_tree)\n",
    "        json_node = {}\n",
    "        json_tree.append(json_node)\n",
    "        json_node['type'] = node_type\n",
    "        children = []\n",
    "        for item in l:\n",
    "            children.append(traverse(item))\n",
    "        if (len(children) != 0):\n",
    "            json_node['children'] = children\n",
    "        return pos\n",
    "        \n",
    "    def traverse(node):\n",
    "        pos = len(json_tree)\n",
    "        json_node = {}\n",
    "        json_tree.append(json_node)\n",
    "        json_node['type'] = type(node).__name__\n",
    "        children = []\n",
    "        if isinstance(node, ast.Name):\n",
    "            json_node['value'] = node.id\n",
    "        elif isinstance(node, ast.Num):\n",
    "            json_node['value'] = str(node.n)\n",
    "        elif isinstance(node, ast.Str):\n",
    "            json_node['value'] = node.s\n",
    "        elif isinstance(node, ast.alias):\n",
    "            json_node['value'] = str(node.name)\n",
    "            if node.asname:\n",
    "                children.append(gen_identifier(node.asname))\n",
    "        elif isinstance(node, ast.FunctionDef):\n",
    "            json_node['value'] = str(node.name)\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            json_node['value'] = str(node.name)\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module:\n",
    "                json_node['value'] = str(node.module)\n",
    "        elif isinstance(node, ast.Global):\n",
    "            for n in node.names:\n",
    "                children.append(gen_identifier(n))\n",
    "        elif isinstance(node, ast.keyword):\n",
    "            json_node['value'] = str(node.arg)\n",
    "        \n",
    "\n",
    "        # Process children.\n",
    "        if isinstance(node, ast.For):\n",
    "            children.append(traverse(node.target))\n",
    "            children.append(traverse(node.iter))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "            if node.orelse:\n",
    "                children.append(traverse_list(node.orelse, 'orelse'))\n",
    "        elif isinstance(node, ast.If) or isinstance(node, ast.While):\n",
    "            children.append(traverse(node.test))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "            if node.orelse:\n",
    "                children.append(traverse_list(node.orelse, 'orelse'))\n",
    "        elif isinstance(node, ast.With):\n",
    "            children.append(traverse(node.context_expr))\n",
    "            if node.optional_vars:\n",
    "                children.append(traverse(node.optional_vars))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "        elif isinstance(node, ast.Try):\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "            children.append(traverse_list(node.handlers, 'handlers'))\n",
    "            if node.orelse:\n",
    "                children.append(traverse_list(node.orelse, 'orelse'))\n",
    "        elif isinstance(node, ast.arguments):\n",
    "            children.append(traverse_list(node.args, 'args'))\n",
    "            children.append(traverse_list(node.defaults, 'defaults'))\n",
    "            if node.vararg:\n",
    "                children.append(gen_identifier(node.vararg, 'vararg'))\n",
    "            if node.kwarg:\n",
    "                children.append(gen_identifier(node.kwarg, 'kwarg'))\n",
    "        elif isinstance(node, ast.ExceptHandler):\n",
    "            if node.type:\n",
    "                children.append(traverse_list([node.type], 'type'))\n",
    "            if node.name:\n",
    "                children.append(traverse_list([node.name], 'name'))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            children.append(traverse_list(node.bases, 'bases'))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "            children.append(traverse_list(node.decorator_list, 'decorator_list'))\n",
    "        elif isinstance(node, ast.FunctionDef):\n",
    "            children.append(traverse(node.args))\n",
    "            children.append(traverse_list(node.body, 'body'))\n",
    "            children.append(traverse_list(node.decorator_list, 'decorator_list'))\n",
    "        else:\n",
    "            # Default handling: iterate over children.\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                if isinstance(child, ast.expr_context) or isinstance(child, ast.operator) or isinstance(child, ast.boolop) or isinstance(child, ast.unaryop) or isinstance(child, ast.cmpop):\n",
    "                    # Directly include expr_context, and operators into the type instead of creating a child.\n",
    "                    json_node['type'] = json_node['type'] + type(child).__name__\n",
    "                else:\n",
    "                    children.append(traverse(child))\n",
    "                \n",
    "        if isinstance(node, ast.Attribute):\n",
    "            children.append(gen_identifier(node.attr, 'attr'))\n",
    "                \n",
    "        if (len(children) != 0):\n",
    "            json_node['children'] = children\n",
    "        return pos\n",
    "    \n",
    "    traverse(tree)\n",
    "    return json_tree\n",
    "\n",
    "def get_param_from_filename(param,filename):\n",
    "    template = \"\\?{}=(.*)\\.|\\?\"\n",
    "    query_regex = re.compile(template.format(param))\n",
    "    try:\n",
    "        return re.findall(query_regex,filename)[0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "    \n",
    "def get_slug_from_file(filename):\n",
    "    return re.split(\"\\?|\\.\",filename)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f55f1b3c9e4ac0beb7336ea43aaefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5434.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_COMPETITION = \"ieee-fraud-detection\"\n",
    "competition_submissions_path = os.path.join(\"../../data/processed/competitions_backup\",TEST_COMPETITION)\n",
    "\n",
    "def replace_function_subtrees(coral_repr):\n",
    "    ignore = []\n",
    "    new_tree = []\n",
    "    for i in range(len(coral_repr)):\n",
    "        node = coral_repr[i]\n",
    "        if i in ignore:\n",
    "            #ignore the children too:\n",
    "            ignore = ignore + node.get(\"children\",[])\n",
    "            continue\n",
    "        elif node[\"type\"] == \"Call\":\n",
    "            ignore = ignore + node.get(\"children\",[])[1:]\n",
    "        new_tree.append(node)\n",
    "    return new_tree\n",
    "            \n",
    "\n",
    "class Cell(object):\n",
    "    def __init__(self,slug,version_id,source):\n",
    "        self.slug = slug\n",
    "        self.version_id = version_id\n",
    "        self.source = source\n",
    "        self.coral_repr = parse_string(source)\n",
    "        self.function_args_removed_repr = replace_function_subtrees(self.coral_repr)\n",
    "        self.python_ast = ast.parse(source)\n",
    "    \n",
    "    def coral_diff(self,other,key = None,attr=\"coral_repr\"):\n",
    "        a_attr = getattr(self,attr)\n",
    "        b_attr = getattr(other,attr)\n",
    "        return self.tree_diff(a_attr, b_attr, key = key)\n",
    "        \n",
    "    def rear_pad_list(a,n):\n",
    "        m = len(a)\n",
    "        return a + [None for i in range(n-m)]\n",
    "    \n",
    "    def make_same_length(a,b):\n",
    "        n = max(len(a),len(b))\n",
    "    \n",
    "        a = rear_pad_list(a,n)\n",
    "        b = rear_pad_list(b,n)\n",
    "    \n",
    "        return (a,b)\n",
    "    \n",
    "    def tree_diff(self,a,b,key=None):\n",
    "        a,b = make_same_length(a,b)\n",
    "        if not key:\n",
    "            key =  lambda aa,bb: not aa == bb\n",
    "        return sum([key(aa,bb) for (aa,bb) in zip(a,b)])\n",
    "    \n",
    "    def __dict__(self):\n",
    "        return {\"slug\":self.slug, \"version_id\" : self.version_id, \n",
    "               \"source\":self.source,\"coral_repr\":self.coral_repr}\n",
    "    \n",
    "kernel_trees = {}\n",
    "\n",
    "#Could also try finding single lines\n",
    "\n",
    "\n",
    "for version_path in tqdm(glob.glob(competition_submissions_path+ \"/*.json\")):\n",
    "    filename = os.path.basename(version_path)\n",
    "    version_id = get_param_from_filename(\"scriptVersionId\",filename)\n",
    "    if not version_id:\n",
    "        continue\n",
    "        \n",
    "    slug = get_slug_from_file(filename)\n",
    "    \n",
    "    if not slug in kernel_trees:\n",
    "        kernel_trees[slug] = {}\n",
    "    \n",
    "    with open(version_path) as kernel_file:\n",
    "        try:\n",
    "            res = json.load(kernel_file)\n",
    "        except ValueError:\n",
    "            continue \n",
    "            \n",
    "        if not \"cells\" in res:\n",
    "            continue\n",
    "            \n",
    "        version_cells = []\n",
    "        \n",
    "        for cell in res[\"cells\"]:\n",
    "            if type(cell[\"source\"]) is list:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                version_cells.append(Cell(slug,version_id,cell[\"source\"]))\n",
    "                                                    \n",
    "            except (SyntaxError, AttributeError):\n",
    "                continue\n",
    "        \n",
    "        kernel_trees[slug][version_id] = version_cells\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rear_pad_list(a,n):\n",
    "    m = len(a)\n",
    "    return a + [None for i in range(n-m)]\n",
    "    \n",
    "def make_same_length(a,b):\n",
    "    n = max(len(a),len(b))\n",
    "    \n",
    "    a = rear_pad_list(a,n)\n",
    "    b = rear_pad_list(b,n)\n",
    "    \n",
    "    return (a,b)\n",
    "    \n",
    "def tree_diff(a,b,key=None):\n",
    "    a,b = make_same_length(a,b)\n",
    "    if not key:\n",
    "        key =  lambda aa,bb: not aa == bb\n",
    "    return sum([key(aa,bb) for (aa,bb) in zip(a,b)])\n",
    "\n",
    "def looks_like_string(node):\n",
    "    node_type = node.get(\"type\")\n",
    "    if node_type == \"Constant\":\n",
    "        try:\n",
    "            float(node.get(\"value\"))\n",
    "            return False\n",
    "        except (ValueError,TypeError):\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def dont_count_strings(a,b):\n",
    "    if a is None or b is None:\n",
    "        return True\n",
    "    if looks_like_string(a) and looks_like_string(b):\n",
    "        return False\n",
    "    else:\n",
    "        return (not a == b)\n",
    "    \n",
    "def get_matching_cells(kernel_trees,diff_versions = False, key = None,attr=\"coral_repr\"):\n",
    "    matches = []\n",
    "    all_cells = []\n",
    "    for slug,versions in tqdm(kernel_trees.items()):\n",
    "        all_version_cells = []\n",
    "        for version_id, cells in versions.items():\n",
    "            if cells:\n",
    "                for cell in cells:\n",
    "                    all_version_cells.append(cell)\n",
    "\n",
    "        n = len(all_version_cells)\n",
    "        if n == 1:\n",
    "            continue\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                    \n",
    "                cell_i = all_version_cells[i]\n",
    "                cell_j = all_version_cells[j]\n",
    "                \n",
    "                if diff_versions:\n",
    "                    if cell_i.version_id == cell_j.version_id:\n",
    "                        continue\n",
    "                diff = cell_i.coral_diff(cell_j,key=key,attr=attr)\n",
    "                if diff == 1:\n",
    "                    matches.append((cell_i,cell_j))\n",
    "        all_cells = all_cells + all_version_cells\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b6e801d77c400fbcebf5b015c7305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matches = get_matching_cells(kernel_trees, diff_versions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table class=\"diff\" id=\"difflib_chg_to6__top\"\n",
       "           cellspacing=\"0\" cellpadding=\"0\" rules=\"groups\" >\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>\n",
       "        \n",
       "        <tbody>\n",
       "            <tr><td class=\"diff_next\" id=\"difflib_chg_to6__0\"><a href=\"#difflib_chg_to6__top\">t</a></td><td class=\"diff_header\" id=\"from6_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_sub\">del&nbsp;raw_train_data</span></td><td class=\"diff_next\"><a href=\"#difflib_chg_to6__top\">t</a></td><td class=\"diff_header\" id=\"to6_1\">1</td><td nowrap=\"nowrap\"><span class=\"diff_add\">featuresToUse</span></td></tr>\n",
       "        </tbody>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_diff((matches[300][0].source),(matches[300][1].source))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_code_diff(a,b):\n",
    "    dmp = diff_match_patch()\n",
    "    diffs = dmp.diff_main(a,b)\n",
    "    dmp.diff_cleanupSemantic(diffs)\n",
    "    display(HTML(dmp.diff_prettyHtml(diffs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">goodCategoricalVars = categoricalCols</del><ins style=\"background:#e6ffe6;\">del train_data,target_data</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches[200][0].source,matches[200][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">test_submission.to_csv('submission_catboost_baseline.csv', index=False</del><ins style=\"background:#e6ffe6;\">pd.set_option('display.max_columns', 500</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches[0][0].source,matches[0][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>corrThresh = 0.</span><del style=\"background:#ffe6e6;\">9</del><ins style=\"background:#e6ffe6;\">6</ins><span>&para;<br># Select upper triangle of correlation matrix&para;<br>upper = correlationMatrix.where(np.triu(np.ones(correlationMatrix.shape), k=1).astype(np.bool))&para;<br>to_drop = [column for column in upper.columns if any(upper[column] &gt; corrThresh)]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches[1000][0].source,matches[1000][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.countplot(train_transaction_data['card</span><del style=\"background:#ffe6e6;\">6</del><ins style=\"background:#e6ffe6;\">4</ins><span>'])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches[6100][0].source,matches[6100][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.countplot(train_transaction_data['</span><del style=\"background:#ffe6e6;\">isFraud</del><ins style=\"background:#e6ffe6;\">card6</ins><span>'])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches[5900][0].source,matches[5900][1].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distribution of these matches like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ieee-cis-fraud-detection                           15316\n",
       "kernel1a76f4bb95                                    9095\n",
       "fraud-detection                                     7929\n",
       "e-d-a-and-baseline-mix-lgbm                         7432\n",
       "ieee-cis-competition-how-to-survive-the-shakeup     6000\n",
       "                                                   ...  \n",
       "lgbm-baseline-features-importance                      1\n",
       "ieee-catboost-baseline-with-groupkfold-cv              1\n",
       "flavour-of-autoencoder-0-0                             1\n",
       "feature-engineered-lightgbm                            1\n",
       "is-it-really-fraud                                     1\n",
       "Length: 160, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slugs = [x[0].slug for x in matches]\n",
    "pd.Series(slugs).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_exclude_slug_bug = list(filter(lambda x: x[0].slug != \"ieee-cis-fraud-detection\", matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>cat_idx = [df_train</span><ins style=\"background:#e6ffe6;\">_con</ins><span>.columns.get_loc(c) for c in cat_cols]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_exclude_slug_bug[20][0].source,matches_exclude_slug_bug[20][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span># This Python 3 environment comes with many helpful analytics libraries installed&para;<br># It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python&para;<br># For example, here's several helpful packages to load in &para;<br>&para;<br>import numpy as np # linear algebra&para;<br>import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)&para;<br>&para;<br># Input data files are available in the \"../input/\" directory.&para;<br># For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory&para;<br>&para;<br>import os&para;<br>import </span><del style=\"background:#ffe6e6;\">gc</del><ins style=\"background:#e6ffe6;\">sys</ins><span>&para;<br>print(os.listdir(\"../input\"))&para;<br>&para;<br># Any results you write to the current directory are saved as output.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_exclude_slug_bug[37][0].source,matches_exclude_slug_bug[37][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "def remove_duplicate_matches(matches):\n",
    "    to_return = []\n",
    "    record = set()\n",
    "    for match in matches:\n",
    "        if not (match[0].source,match[1].source) in record:\n",
    "            record.add((match[0].source,match[1].source))\n",
    "            to_return.append(match)\n",
    "    return to_return\n",
    "matches_no_dups = remove_duplicate_matches(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>na_vals = np.sum(raw_train_data.loc[:,variables]==-1)/raw_train_data.shape[0]&para;<br>goodNumericVars = []&para;<br>for i_var in variables:    &para;<br>    if na_vals[i_var] &lt; 0.8</span><del style=\"background:#ffe6e6;\">5</del><ins style=\"background:#e6ffe6;\">0</ins><span>:        &para;<br>        goodNumericVars.append(i_var)&para;<br>goodNumericVars.remove('TransactionDT')&para;<br>goodNumericVars.remove('TransactionID')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[40][0].source,matches_no_dups[40][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">goodN</del><ins style=\"background:#e6ffe6;\">n</ins><span>umeric</span><del style=\"background:#ffe6e6;\">Var</del><ins style=\"background:#e6ffe6;\">_column</ins><span>s</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[50][0].source,matches_no_dups[50][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>from sklearn.model_selection import StratifiedKFold,</span><del style=\"background:#ffe6e6;\">train_test_split</del><ins style=\"background:#e6ffe6;\">GroupKFold</ins><span>&para;<br>from sklearn.metrics import roc_curve, auc&para;<br>from lightgbm import LGBMClassifier&para;<br>import lightgbm as lgb&para;<br>&para;<br></span><ins style=\"background:#e6ffe6;\">#group_kfold = GroupKFold(n_splits=5)&para;<br></ins><span>cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[55][0].source,matches_no_dups[55][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>'''</span><del style=\"background:#ffe6e6;\">LGB_BO.max['params']</del><ins style=\"background:#e6ffe6;\">bound_lgb = {'num_leaves': (70,600),&para;<br>              'min_child_weight': (0.001, 0.07),&para;<br>              'feature_fraction': (0.1,0.9),&para;<br>              'bagging_fraction': (0.1,0.9),&para;<br>              'max_depth': (-1,50),&para;<br>              'learning_rate': (0.2,0.9),&para;<br>              'reg_alpha': (0.3,0.9),&para;<br>              'reg_lambda': (0.3,0.9),&para;<br>              'min_data_in_leaf':(50,300)&para;<br>         }</ins><span>'''</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[556][0].source,matches_no_dups[556][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>'''LGB_BO</span><del style=\"background:#ffe6e6;\">.max['params']</del><ins style=\"background:#e6ffe6;\"> = BayesianOptimization(objective, bound_lgb, random_state=42)</ins><span>'''</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[557][0].source,matches_no_dups[557][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>ploting_cnt_amt(train_transaction, '</span><del style=\"background:#ffe6e6;\">_Days</del><ins style=\"background:#e6ffe6;\">addr2</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[600][0].source,matches_no_dups[600][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>plotTrnCategoryRateBar('</span><del style=\"background:#ffe6e6;\">card5</del><ins style=\"background:#e6ffe6;\">R_emaildomain</ins><span>',</span><del style=\"background:#ffe6e6;\"> </del><span>10)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[700][0].source,matches_no_dups[700][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>train_trans[d</span><ins style=\"background:#e6ffe6;\">ist</ins><span>_col].head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[1000][0].source,matches_no_dups[1000][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>plot_c_feature(train, '</span><del style=\"background:#ffe6e6;\">id_17</del><ins style=\"background:#e6ffe6;\">M6</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_no_dups[5000][0].source,matches_no_dups[5000][1].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c718b471c2ad4d32941951b606af2e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "line_trees = {}\n",
    "\n",
    "for slug,versions in tqdm(kernel_trees.items()):\n",
    "    version_lines = []\n",
    "    line_trees[slug] = {}\n",
    "    for version_id, cells in versions.items():\n",
    "        version_lines = []\n",
    "        if cells:\n",
    "            for cell in cells:\n",
    "                for line in cell.source.split(\"\\n\"):\n",
    "                    try:\n",
    "                        version_lines.append(Cell(slug,version_id,line))\n",
    "                    except SyntaxError:\n",
    "                        continue\n",
    "        line_trees[slug][version_id] = version_lines\n",
    "    \n",
    "\n",
    "# def get_matching_cells(kernel_trees):\n",
    "#     matches = []\n",
    "#     all_cells = []\n",
    "#     for slug,versions in tqdm(kernel_trees.items()):\n",
    "#         all_version_cells = []\n",
    "#         for version_id, cells in versions.items():\n",
    "#             if cells:\n",
    "#                 for cell in cells:\n",
    "#                     all_version_cells.append(cell)\n",
    "\n",
    "#         n = len(all_version_cells)\n",
    "#         if n == 1:\n",
    "#             continue\n",
    "#         for i in range(n):\n",
    "#             for j in range(i+1,n):\n",
    "#                 cell_i = all_version_cells[i]\n",
    "#                 cell_j = all_version_cells[j]\n",
    "\n",
    "#                 diff = cell_i.coral_diff(cell_j)\n",
    "#                 if diff == 1:\n",
    "#                     matches.append((cell_i,cell_j))\n",
    "#         all_cells = all_cells + all_version_cells\n",
    "#     return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dbeb2dd7124e8f89feb9535d75ae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "line_matches = get_matching_cells(line_trees, diff_versions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>goodCategoricalVars.append('card1_</span><del style=\"background:#ffe6e6;\">card2</del><ins style=\"background:#e6ffe6;\">P_emaildomain</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 8007\n",
    "pprint_code_diff(line_matches[i][0].source,line_matches[i][1].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe don't count strings?\n",
    "These tend to be too specific to the dataset IMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24397272f844169ad4aeacb63f393ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matches_ignore_strings = get_matching_cells(kernel_trees, diff_versions = True, key = dont_count_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ignore_strings = remove_duplicate_matches(matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-5f167bdb9975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpprint_code_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches_ignore_strings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches_ignore_strings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[i][0].source,matches_ignore_strings[i][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span># This Python 3 environment comes with many helpful analytics libraries installed&para;<br># It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python&para;<br># For example, here's several helpful packages to load in &para;<br>&para;<br>import numpy as np # linear algebra&para;<br>import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)&para;<br>&para;<br># Input data files are available in the \"../input/\" directory.&para;<br># For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory&para;<br>&para;<br>import os&para;<br>import </span><del style=\"background:#ffe6e6;\">gc</del><ins style=\"background:#e6ffe6;\">sys</ins><span>&para;<br>print(os.listdir(\"../input\"))&para;<br>&para;<br># Any results you write to the current directory are saved as output.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[20][0].source,matches_ignore_strings[20][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.countplot(train_</span><del style=\"background:#ffe6e6;\">transaction_data['card4</del><ins style=\"background:#e6ffe6;\">identity_data['DeviceType</ins><span>'])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[1000][0].source,matches_ignore_strings[1000][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.set(rc={'figure.figsize':(40,40)})&para;<br>corr=df_train[FF[</span><del style=\"background:#ffe6e6;\">4</del><ins style=\"background:#e6ffe6;\">5</ins><span>]+['isFraud']].corr()&para;<br>plt.figure() &para;<br>ax = sns.heatmap(corr,linewidths=.5, annot=True,cmap=\"YlGnBu\")</span><del style=\"background:#ffe6e6;\">&para;<br></del>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[9000][0].source,matches_ignore_strings[9000][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>train_transaction.groupby('ProductCD')</span><del style=\"background:#ffe6e6;\"> \\&para;<br>    ['TransactionID'].count</del><ins style=\"background:#e6ffe6;\">['isFraud'] \\&para;<br>    .mean</ins><span>() \\&para;<br>    .sort_index() \\&para;<br>    .plot(kind='barh',&para;<br>          figsize=(15, 3),&para;<br>         title='</span><del style=\"background:#ffe6e6;\">Count of Observations</del><ins style=\"background:#e6ffe6;\">Percentage of Fraud</ins><span> by ProductCD')&para;<br>plt.show()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[1050][0].source,matches_ignore_strings[1050][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>df_transactionraw['</span><del style=\"background:#ffe6e6;\">american express'].uniqu</del><ins style=\"background:#e6ffe6;\">C3'].describ</ins><span>e()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[2555][0].source,matches_ignore_strings[2555][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>get_</span><del style=\"background:#ffe6e6;\">bar_</del><span>subplots('id_1</span><del style=\"background:#ffe6e6;\">2</del><ins style=\"background:#e6ffe6;\">1</ins><span>','id_1</span><del style=\"background:#ffe6e6;\">5</del><ins style=\"background:#e6ffe6;\">3</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[1555][0].source,matches_ignore_strings[1555][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.set(rc={'figure.figsize':(40,40)})&para;<br>corr=df_train[FF[</span><del style=\"background:#ffe6e6;\">4</del><ins style=\"background:#e6ffe6;\">7</ins><span>]+['isFraud']].corr()&para;<br>plt.figure() &para;<br>ax = sns.heatmap(corr,linewidths=.5, annot=True,cmap=\"YlGnBu\")</span><del style=\"background:#ffe6e6;\">&para;<br></del>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[155][0].source,matches_ignore_strings[155][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>train</span><ins style=\"background:#e6ffe6;\">_transaction</ins><span>.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[322][0].source,matches_ignore_strings[322][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>metadata(train_trans[</span><del style=\"background:#ffe6e6;\">dist</del><ins style=\"background:#e6ffe6;\">m</ins><span>_col])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[422][0].source,matches_ignore_strings[422][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>metadata(train_trans[</span><del style=\"background:#ffe6e6;\">email</del><ins style=\"background:#e6ffe6;\">card</ins><span>_col])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint_code_diff(matches_ignore_strings[450][0].source,matches_ignore_strings[450][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Module', 'children': [1]},\n",
       " {'type': 'Expr', 'children': [2]},\n",
       " {'type': 'Call', 'children': [3, 4]},\n",
       " {'type': 'NameLoad', 'value': 'metadata'},\n",
       " {'type': 'SubscriptLoad', 'children': [5, 6]},\n",
       " {'type': 'NameLoad', 'value': 'train_trans'},\n",
       " {'type': 'Index', 'children': [7]},\n",
       " {'type': 'NameLoad', 'value': 'emailcard_col'}]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_string(\"metadata(train_trans[emailcard_col])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Module', 'children': [1]},\n",
       " {'type': 'Assign', 'children': [2, 3]},\n",
       " {'type': 'NameStore', 'value': 'df'},\n",
       " {'type': 'Call', 'children': [4]},\n",
       " {'type': 'AttributeLoad', 'children': [5, 6]},\n",
       " {'type': 'NameLoad', 'value': 'df'},\n",
       " {'type': 'attr', 'value': 'drop_duplicates'}]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_string(\"df = df.drop_duplicates()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines where we don't count strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d0e59aa45f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mline_matches_ignore_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matching_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_versions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdont_count_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'line_trees' is not defined"
     ]
    }
   ],
   "source": [
    "line_matches_ignore_strings = get_matching_cells(line_trees, diff_versions = True, key = dont_count_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_matches_ignore_strings = remove_duplicate_matches(line_matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random(k,matches):\n",
    "    n = len(matches)\n",
    "    indices = np.random.choice(range(n),k,replace = False)\n",
    "    for i in indices:\n",
    "        pprint_code_diff(matches[i][0].source,matches[i][1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>m</span><del style=\"background:#ffe6e6;\">any_na</del><ins style=\"background:#e6ffe6;\">ore_than_90_NA_or_same_value</ins><span>_test=[]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>del train_</span><del style=\"background:#ffe6e6;\">3</del><ins style=\"background:#e6ffe6;\">5</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>plt.</span><del style=\"background:#ffe6e6;\">ylabel('</del><ins style=\"background:#e6ffe6;\">title('Target variable </ins><span>count')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>test_</span><del style=\"background:#ffe6e6;\">transaction</del><ins style=\"background:#e6ffe6;\">identity</ins><span> = pd.read_csv('/</span><del style=\"background:#ffe6e6;\">/</del><span>kaggle/input/ieee-fraud-detection/test_</span><del style=\"background:#ffe6e6;\">transaction</del><ins style=\"background:#e6ffe6;\">identity</ins><span>.csv', index_col='TransactionID')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>test</span><ins style=\"background:#e6ffe6;\">_tr</ins><span>.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>print(</span><del style=\"background:#ffe6e6;\">\"Shape of Test_identity:: \", test_identity</del><ins style=\"background:#e6ffe6;\">'test shape:', test</ins><span>.shape)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">df_transactionraw['R</del><ins style=\"background:#e6ffe6;\">test['M3</ins><span>'].unique()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">test</del><ins style=\"background:#e6ffe6;\">Y_train</ins><span>.isna().sum()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">submission</del><ins style=\"background:#e6ffe6;\">test_df</ins><span>.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>train['</span><del style=\"background:#ffe6e6;\">uid_</del><span>device_</span><ins style=\"background:#e6ffe6;\">uid_</ins><span>nunique'] = train.</span><del style=\"background:#ffe6e6;\">uid1</del><ins style=\"background:#e6ffe6;\">device_hash</ins><span>.map(tmp.to_dict()['nunique'])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(10, line_matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>corr=df_train[FF[11]+['isFraud']].co</span><del style=\"background:#ffe6e6;\">rr</del><ins style=\"background:#e6ffe6;\">v</ins><span>()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>test_</span><del style=\"background:#ffe6e6;\">identity_data</del><ins style=\"background:#e6ffe6;\">t</ins><span> = pd.read_csv('../input/</span><del style=\"background:#ffe6e6;\">test_identity</del><ins style=\"background:#e6ffe6;\">ieee-fraud-detection/test_transaction</ins><span>.csv')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>t</span><del style=\"background:#ffe6e6;\">rain['M4</del><ins style=\"background:#e6ffe6;\">est['DeviceInfo</ins><span>'].fillna(\"</span><del style=\"background:#ffe6e6;\">Match_</del><span>Missing\",inplace=True)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>g</span><del style=\"background:#ffe6e6;\">2</del><ins style=\"background:#e6ffe6;\">1</ins><span>.set_ylabel(\"Count\", fontsize=17)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>find_percentage(top</span><del style=\"background:#ffe6e6;\">1</del><ins style=\"background:#e6ffe6;\">2</ins><span>0_</span><del style=\"background:#ffe6e6;\">Device_Type,['DeviceType</del><ins style=\"background:#e6ffe6;\">R_email,['R_emaildomain</ins><span>'],fig_size,rotation)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>train_trans[</span><del style=\"background:#ffe6e6;\">ad</del><span>d_col].head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>t</span><del style=\"background:#ffe6e6;\">rain['addr2</del><ins style=\"background:#e6ffe6;\">est['M3</ins><span>'].fillna(\"Missing\",inplace=True)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">sample_submission_csv</del><ins style=\"background:#e6ffe6;\">train_transaction</ins><span>.shape</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>train_trans[</span><del style=\"background:#ffe6e6;\">card</del><ins style=\"background:#e6ffe6;\">email</ins><span>_col].describe()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>from sklearn.metrics import </span><del style=\"background:#ffe6e6;\">confusion_matrix</del><ins style=\"background:#e6ffe6;\">roc_auc_score</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(10, line_matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches_ignore_strings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-166eee79c02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches_ignore_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'matches_ignore_strings' is not defined"
     ]
    }
   ],
   "source": [
    "display_random(1,matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">labels</del><ins style=\"background:#e6ffe6;\">\"\"\"clf = xgb.XGBClassifier(random_state=42,n_jobs=-1,verbosity=1)&para;<br>params = {\"max_depth\":[3,5,7,9],&para;<br>          \"n_estimators\":list(range(50,301,50)),&para;<br>          \"learning_rate\":[0.01,0.05,0.1,0.3],&para;<br>          \"subsample\":[0.5,0.7,0.9],&para;<br>          \"colsample_bytree\":[0.5,0.7,0.9],&para;<br>          \"reg_alpha\":[0.5,1,2,5],&para;<br>          \"reg_lambda\":[0.5,1,2,5]}&para;<br>random_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=5,scoring='roc_auc')&para;<br>random_search.fit(X_Train,y_Train)\"\"\"</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">X_tes</del><ins style=\"background:#e6ffe6;\">sumbmi</ins><span>t.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>randSearchCV.best_</span><del style=\"background:#ffe6e6;\">estimator</del><ins style=\"background:#e6ffe6;\">params</ins><span>_</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>train_trans[c</span><ins style=\"background:#e6ffe6;\">ard</ins><span>_col].describe()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">plot_hist('addr1</del><ins style=\"background:#e6ffe6;\">TimeSeriesPlot('C3</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>get_</span><del style=\"background:#ffe6e6;\">bar_</del><span>subplots('</span><del style=\"background:#ffe6e6;\">id_38','id_37</del><ins style=\"background:#e6ffe6;\">D1','D2</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(6,matches_ignore_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_matches = list(filter(lambda x: len(x[0].source) > 100, matches_ignore_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>import lightgbm as lgb&para;<br>model_lgb = lgb.LGBMClassifier(bagging_fraction=0.4181193142567742, bagging_seed=11,&para;<br>                               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,&para;<br>                               feature_fraction=0.3797454081646243, importance_type='split',&para;<br>                               learning_rate=0.006883242363721497, max_depth=-1, metric='auc',&para;<br>                               min_child_samples=20, min_child_weight=0.03454472573214212,&para;<br>                               min_data_in_leaf=106, min_split_gain=0.0, n_estimators=100,&para;<br>                               n_jobs=-1, num_boost_round=</span><del style=\"background:#ffe6e6;\">5090</del><ins style=\"background:#e6ffe6;\">1581</ins><span>, num_leaves=491,&para;<br>                               objective='binary', random_state=47,&para;<br>                               reg_alpha=0.3899927210061127, reg_lambda=0.6485237330340494,&para;<br>                               silent=True, subsample=1.0, subsample_for_bin=200000,&para;<br>                               subsample_freq=0, verbosity=-1)&para;<br>model_lgb.fit(train,Y)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>print(lightGBM_bo.space.keys)&para;<br>init_points = 10&para;<br>n_iter = </span><del style=\"background:#ffe6e6;\">15</del><ins style=\"background:#e6ffe6;\">30</ins><span>&para;<br>print('-' * 130)&para;<br>&para;<br>lightGBM_bo.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):&para;<br>    xgbclf = xgb.XGBClassifier(&para;<br>        n_estimators=</span><del style=\"background:#ffe6e6;\">5</del><ins style=\"background:#e6ffe6;\">10</ins><span>00,&para;<br>        max_depth=10,&para;<br>        learning_rate=0.048,&para;<br>        subsample=0.85,&para;<br>        colsample_bytree=0.85,&para;<br>        missing=-999,&para;<br>        tree_method='gpu_hist',  # THE MAGICAL PARAMETER&para;<br>        reg_alpha=0.15,&para;<br>        reg_lamdba=0.85&para;<br>    )&para;<br>    &para;<br>    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]&para;<br>    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]&para;<br>    xgbclf.fit(X_train,y_train,verbose=50)&para;<br>    pred=xgbclf.predict_proba(test)[:,1]&para;<br>    val=xgbclf.predict_proba(X_valid)[:,1]&para;<br>    print('Fold {}:ROC accuracy: {}'.format(fold_n,roc_auc_score(y_valid, val)))&para;<br>    xgb_submission['isFraud'] = xgb_submission['isFraud']+pred/n_fold&para;<br></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>train_transaction.groupby('ProductCD')</span><del style=\"background:#ffe6e6;\"> \\&para;<br>    ['TransactionID'].count</del><ins style=\"background:#e6ffe6;\">['isFraud'] \\&para;<br>    .mean</ins><span>() \\&para;<br>    .sort_index() \\&para;<br>    .plot(kind='barh',&para;<br>          figsize=(15, 3),&para;<br>         title='</span><del style=\"background:#ffe6e6;\">Count of Observations</del><ins style=\"background:#e6ffe6;\">Percentage of Fraud</ins><span> by ProductCD')&para;<br>plt.show()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span># </span><del style=\"background:#ffe6e6;\">plot bar graphs to visualize the number of transaction and fraud transaction percentage for each mo</del><ins style=\"background:#e6ffe6;\">find out the number of transactions for addr2 categories with the top 20 transaction count &para;<br># find out the fraud transaction percentage of total transactions for addr2 categories with the top 20 transaction cou</ins><span>nt</span><del style=\"background:#ffe6e6;\">h</del><ins style=\"background:#e6ffe6;\"> </ins><span>&para;<br>find_percentage(</span><del style=\"background:#ffe6e6;\">raw_train_transaction,['Month'</del><ins style=\"background:#e6ffe6;\">top20_addr2,[\"addr2\"</ins><span>],fig_size,rotation)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>from imblearn.over_sampling import RandomOverSampler&para;<br>&para;<br>print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))&para;<br>print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))&para;<br>&para;<br>sm = RandomOverSampler(random_state=999, sampling_strategy = 0.1</span><ins style=\"background:#e6ffe6;\">3</ins><span>)&para;<br>X_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())&para;<br>&para;<br>X_train_new = pd.DataFrame(X_train_new)&para;<br>X_train_new.columns = X_train.columns&para;<br>y_train_new = pd.DataFrame(y_train_new)&para;<br>&para;<br>print('After OverSampling, the shape of X_train_new: {}'.format(X_train_new.shape))&para;<br>print('After OverSampling, the shape of y_train_new: {} \\n'.format(y_train_new.shape))</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,big_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_matches = list(filter(lambda x: len(x[0].source) > 50 and len(x[0].source) < 100 , matches_ignore_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>count_perFraud_plots(train_trans,'</span><del style=\"background:#ffe6e6;\">id_12</del><ins style=\"background:#e6ffe6;\">DeviceType</ins><span>',False,</span><ins style=\"background:#e6ffe6;\"> </ins><span>fontsize=1</span><del style=\"background:#ffe6e6;\">4</del><ins style=\"background:#e6ffe6;\">2</ins><span>, figsizeW= 12, figsizeH= 22)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>train_trans</span><del style=\"background:#ffe6e6;\">_reduced</del><ins style=\"background:#e6ffe6;\">action</ins><span>['isFraud'].value_counts().plot(kind='bar', title=\"</span><del style=\"background:#ffe6e6;\">After</del><ins style=\"background:#e6ffe6;\">Before</ins><span> cleaning\")</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>t</span><del style=\"background:#ffe6e6;\">rain</del><ins style=\"background:#e6ffe6;\">est</ins><span>['P_emaildomain'].value_counts(dropna=False).head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>res = res[res[:, 1] &gt; 0.000</span><del style=\"background:#ffe6e6;\">15</del><ins style=\"background:#e6ffe6;\">2</ins><span>]&para;<br>res_columns = res[:, 0]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>merge_df_test.loc[merge_df_test['card</span><del style=\"background:#ffe6e6;\">3</del><ins style=\"background:#e6ffe6;\">4</ins><span>'].isna(),'card</span><del style=\"background:#ffe6e6;\">3</del><ins style=\"background:#e6ffe6;\">4</ins><span>']=</span><del style=\"background:#ffe6e6;\">150</del><ins style=\"background:#e6ffe6;\">'visa' </ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>submission['isFraud'] = ec.predict</span><ins style=\"background:#e6ffe6;\">_proba</ins><span>(X_test)[:,1]&para;<br>submission.to_csv('ec_3_in_1.csv')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>print('Mean </span><del style=\"background:#ffe6e6;\">F1-</del><ins style=\"background:#e6ffe6;\">AUC </ins><span>Score : {}'.format(np.array(cv_score</span><del style=\"background:#ffe6e6;\">_lgb</del><span>).mean()))</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span>plot_feature_importances(feature_importances, train</span><del style=\"background:#ffe6e6;\">_x_en</del><span>.columns)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\"># Don't see any strings here, looks like the encoding worked&para;<br>train</del><ins style=\"background:#e6ffe6;\">train_identity</ins><span>.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(5,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>print(\"mean </span><ins style=\"background:#e6ffe6;\">temporal CV </ins><span>AUC\",cross_val_score(clf, X_train,y_train, cv=kf</span><ins style=\"background:#e6ffe6;\">_time</ins><span>, scoring='roc_auc').mean())</span><del style=\"background:#ffe6e6;\">&para;<br></del>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.catplot(x=\"</span><del style=\"background:#ffe6e6;\">card4</del><ins style=\"background:#e6ffe6;\">DeviceType</ins><span>\", y=\"TransactionAmt\", hue=\"isFraud\",kind=\"</span><del style=\"background:#ffe6e6;\">bar</del><ins style=\"background:#e6ffe6;\">violin</ins><span>\", data=t</span><del style=\"background:#ffe6e6;\">emp</del><ins style=\"background:#e6ffe6;\">rain</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">&para;<br></del><span>sns.catplot(x=\"</span><del style=\"background:#ffe6e6;\">card4</del><ins style=\"background:#e6ffe6;\">ProductCD</ins><span>\", y=\"TransactionAmt\", hue=\"isFraud\",</span><ins style=\"background:#e6ffe6;\"> </ins><span>kind=\"bar\", data=t</span><del style=\"background:#ffe6e6;\">emp</del><ins style=\"background:#e6ffe6;\">rain</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>sns.catplot(x=\"</span><del style=\"background:#ffe6e6;\">ProductCD</del><ins style=\"background:#e6ffe6;\">card4</ins><span>\", y=\"TransactionAmt\", hue=\"isFraud\",</span><del style=\"background:#ffe6e6;\"> </del><span>kind=\"bar\", data=t</span><del style=\"background:#ffe6e6;\">rain</del><ins style=\"background:#e6ffe6;\">emp</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>count_perFraud_plots(train_trans,'id_</span><del style=\"background:#ffe6e6;\">35</del><ins style=\"background:#e6ffe6;\">12</ins><span>',False,fontsize=14, figsizeW= 12, figsizeH= 2</span><del style=\"background:#ffe6e6;\">0</del><ins style=\"background:#e6ffe6;\">2</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,medium_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_ge = big_matches + medium_matches\n",
    "for_ge_trees = [(x.source,y.source) for x,y in for_ge]\n",
    "pickled_trees = pickle.dump(for_ge_trees,open(\"source_pairs.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"EPOCHS = 5\\ny_pred = np.zeros(sample_submission.shape[0])\\ny_oof = np.zeros(X_train.shape[0])\\nkf = KFold(n_splits = EPOCHS , shuffle = True)\\nfor x_train_index , x_val_index in kf.split(X_train , Y_train):\\n    clf = xgb.XGBClassifier(\\n        n_estimators=500,\\n        max_depth=4,\\n        learning_rate=0.005,\\n        subsample=0.2,\\n        colsample_bytree = 0.2\\n    )\\n    x_tr , x_val = X_train.iloc[x_train_index , :] , X_train.iloc[x_val_index,:]\\n    y_tr , y_val = Y_train.iloc[x_train_index] , Y_train.iloc[x_val_index]\\n    clf.fit(x_tr,y_tr)\\n    y_pred_train = clf.predict_proba(x_val)[:,1]\\n    y_oof[x_val_index] = y_pred_train\\n    print('ROC AUC {}'.format(roc_auc_score(y_val, y_pred_train)))\\n    y_pred+= clf.predict_proba(X_test)[:,1] / EPOCHS\\n\\n \",\n",
       " \"EPOCHS = 3\\ny_pred = np.zeros(sample_submission.shape[0])\\ny_oof = np.zeros(X_train.shape[0])\\nkf = KFold(n_splits = EPOCHS , shuffle = True)\\nfor x_train_index , x_val_index in kf.split(X_train , Y_train):\\n    clf = xgb.XGBClassifier(\\n        n_estimators=500,\\n        max_depth=4,\\n        learning_rate=0.005,\\n        subsample=0.2,\\n        colsample_bytree = 0.2\\n    )\\n    x_tr , x_val = X_train.iloc[x_train_index , :] , X_train.iloc[x_val_index,:]\\n    y_tr , y_val = Y_train.iloc[x_train_index] , Y_train.iloc[x_val_index]\\n    clf.fit(x_tr,y_tr)\\n    y_pred_train = clf.predict_proba(x_val)[:,1]\\n    y_oof[x_val_index] = y_pred_train\\n    print('ROC AUC {}'.format(roc_auc_score(y_val, y_pred_train)))\\n    y_pred+= clf.predict_proba(X_test)[:,1] / EPOCHS\\n\\n \")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_ge_trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting to look promising\n",
    "- Maybe we oversample the large \"alternatives\"?\n",
    "- Should also limiting ourselves to the \"best\" match for each cell \n",
    "      * (df = df.interpolate(), df = df.dropna()) or (df = df.interpolate(), training = df.interpolate())\n",
    "- As per Tim's suggestion let's look at patterns that we're more familiar with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_search_matches(regex,matches):\n",
    "    regex = re.compile(regex)\n",
    "    to_return = []\n",
    "    for a,b in matches:\n",
    "        source_a = a.source\n",
    "        source_b = b.source\n",
    "        \n",
    "        if re.match(regex,source_a) or re.match(regex,source_b):\n",
    "            to_return.append((a,b))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_logistic_regression = regex_search_matches(r\".*transaction.*\",matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span>sns.countplot(train_transaction_data['card</span><del style=\"background:#ffe6e6;\">6</del><ins style=\"background:#e6ffe6;\">4</ins><span>'])</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(has_logistic_regression))\n",
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidebar: How many slugs are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([bool(x) for x in kernel_trees.values()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we don't count the arguments to functions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, {'type': 'Module', 'children': [1, 4, 8]})\n",
      "(1, {'type': 'Assign', 'children': [2, 3]})\n",
      "(2, {'type': 'NameStore', 'value': 'SEED'})\n",
      "(3, {'type': 'Constant', 'value': '42'})\n",
      "(4, {'type': 'Expr', 'children': [5]})\n",
      "(5, {'type': 'Call', 'children': [6, 7]})\n",
      "(6, {'type': 'NameLoad', 'value': 'seed_everything'})\n",
      "(7, {'type': 'NameLoad', 'value': 'SEED'})\n",
      "(8, {'type': 'Assign', 'children': [9, 10]})\n",
      "(9, {'type': 'NameStore', 'value': 'LOCAL_TEST'})\n",
      "(10, {'type': 'Constant'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=0\n",
    "\n",
    "[print(x) for x in list(enumerate(list(list(kernel_trees.values())[index].values())[5][2].coral_repr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################### Vars\n",
      "#################################################################################\n",
      "SEED = 42\n",
      "seed_everything(SEED)\n",
      "LOCAL_TEST = False\n"
     ]
    }
   ],
   "source": [
    "print(list(list(kernel_trees.values())[index].values())[5][2].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab5b2a32590447990d6ba528c5e07ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ignoring_subtrees = get_matching_cells(kernel_trees,attr=\"function_args_removed_repr\", key = dont_count_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace_function_subtrees() missing 1 required positional argument: 'coral_repr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1c68bd8d5e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoral_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreplace_function_subtrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: replace_function_subtrees() missing 1 required positional argument: 'coral_repr'"
     ]
    }
   ],
   "source": [
    "test_tree = list(list(kernel_trees.values())[index].values())[5][2].coral_repr\n",
    "replace_function_subtrees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>plot</span><del style=\"background:#ffe6e6;\">Num</del><ins style=\"background:#e6ffe6;\">Cat</ins><span>('test',test_combined,</span><del style=\"background:#ffe6e6;\">num</del><ins style=\"background:#e6ffe6;\">cat</ins><span>Fields)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>count_perFraud_plots(train_trans,'</span><del style=\"background:#ffe6e6;\">id_12',False,fontsize=14, figsizeW= 12, figsizeH=</del><ins style=\"background:#e6ffe6;\">D14', True, 'quantile',0.750, 12, 14,</ins><span> 22)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>print(</span><del style=\"background:#ffe6e6;\">'the unique device types are:',</del><span>train_identity_data.</span><del style=\"background:#ffe6e6;\">DeviceType.unique()</del><ins style=\"background:#e6ffe6;\">columns</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>plot</span><del style=\"background:#ffe6e6;\">Num('train',train_combined,['TransactionAmt']</del><ins style=\"background:#e6ffe6;\">Cat('test',test_combined,catFields</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">print('Train shape: {}  Test shape: {}'.format(_train.shape, _test.shape)</del><ins style=\"background:#e6ffe6;\">TimeSeriesPlot('C3'</ins><span>)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>t</span><del style=\"background:#ffe6e6;\">rain['M4</del><ins style=\"background:#e6ffe6;\">est['DeviceType</ins><span>'].value_counts(dropna=False)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>visualize_</span><del style=\"background:#ffe6e6;\">cat_c</del><ins style=\"background:#e6ffe6;\">num_v</ins><span>ariable('</span><del style=\"background:#ffe6e6;\">M4</del><ins style=\"background:#e6ffe6;\">dist2</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">sample_submission_csv</del><ins style=\"background:#e6ffe6;\">test</ins><span>.shape</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>get_</span><ins style=\"background:#e6ffe6;\">bar_</ins><span>subplots('</span><del style=\"background:#ffe6e6;\">C11','C12</del><ins style=\"background:#e6ffe6;\">id_28','id_29</ins><span>')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>t</span><del style=\"background:#ffe6e6;\">est['addr2</del><ins style=\"background:#e6ffe6;\">rain['P_emaildomain</ins><span>'].value_counts(dropna=False).head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,ignoring_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_no_subtrees = remove_duplicate_matches([x for x in ignoring_subtrees if len(x[0].source.split(\"\\n\")) > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>variables = list(categoricalCols)&para;<br>na_vals = np.sum(raw_train_data.loc[:,variables]=='missing')/raw_train_data.shape[0]&para;<br>goodCategoricalVars = []&para;<br>for i_var in variables:    &para;<br>    if na_vals[i_var] &lt; </span><del style=\"background:#ffe6e6;\">0.8</del><ins style=\"background:#e6ffe6;\">1</ins><span>:        &para;<br>        goodCategoricalVars.append(i_var)</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,large_no_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_no_subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"EPOCHS = 5\\ny_pred = np.zeros(sample_submission.shape[0])\\ny_oof = np.zeros(X_train.shape[0])\\nkf = KFold(n_splits = EPOCHS , shuffle = True)\\nfor x_train_index , x_val_index in kf.split(X_train , Y_train):\\n    clf = xgb.XGBClassifier(\\n        n_estimators=500,\\n        max_depth=4,\\n        learning_rate=0.005,\\n        subsample=0.2,\\n        colsample_bytree = 0.2\\n    )\\n    x_tr , x_val = X_train.iloc[x_train_index , :] , X_train.iloc[x_val_index,:]\\n    y_tr , y_val = Y_train.iloc[x_train_index] , Y_train.iloc[x_val_index]\\n    clf.fit(x_tr,y_tr)\\n    y_pred_train = clf.predict_proba(x_val)[:,1]\\n    y_oof[x_val_index] = y_pred_train\\n    print('ROC AUC {}'.format(roc_auc_score(y_val, y_pred_train)))\\n    y_pred+= clf.predict_proba(X_test)[:,1] / EPOCHS\\n\\n \""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignoring_subtrees[0][0].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">check_transact</del><ins style=\"background:#e6ffe6;\">sample_submiss</ins><span>ion.head()</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>\"\"\"</span><del style=\"background:#ffe6e6;\">ser = pd.Series(random_search.best_estimator_.feature_importances_,X_Train.columns).sort_values()&para;<br>plt.figure(figsize=(10,10))&para;<br>ser.plot(kind='bar'</del><ins style=\"background:#e6ffe6;\">clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',random_state=42,class_weight='balanced',n_jobs=-1,verbose=1)&para;<br>params = {\"max_depth\":[3,4,5,6,-1],&para;<br>          \"learning_rate\":[0.01,0.05,0.1,0.3],&para;<br>          \"subsample\":[0.5,0.7,0.9],&para;<br>          \"colsample_bytree\":[0.5,0.7,0.9],&para;<br>          \"reg_alpha\":[0.5,1,2],&para;<br>          \"reg_lambda\":[0.5,1,2],&para;<br>          \"num_leaves\":[7,15,31,63],&para;<br>          \"n_estimators\":list(range(50,300,50))}&para;<br>random_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=5,scoring='roc_auc')&para;<br>random_search.fit(X_Train,y_Train</ins><span>)\"\"\"</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span>\"\"\"</span><del style=\"background:#ffe6e6;\">clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',random_state=42,class_weight='balanced',n_jobs=-1,verbose=1)&para;<br>params = {\"max_depth\":[3,4,5,6,-1],&para;<br>          \"learning_rate\":[0.01,0.05,0.1,0.3],&para;<br>          \"subsample\":[0.5,0.7,0.9],&para;<br>          \"colsample_bytree\":[0.5,0.7,0.9],&para;<br>          \"reg_alpha\":[0.5,1,2],&para;<br>          \"reg_lambda\":[0.5,1,2],&para;<br>          \"num_leaves\":[7,15,31,63]</del><ins style=\"background:#e6ffe6;\">&para;<br>n_rows, n_cols =  7, 2&para;<br>&para;<br>fig = make_subplots(rows=n_rows, cols=n_cols)&para;<br>&para;<br>cols = [ 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']&para;<br>i=0&para;<br>for r in range(1, n_rows+1):&para;<br>    for c in range(1, n_cols+1):&para;<br>        if i &gt;= len(cols): continue&para;<br>        feature = cols[i]&para;<br>        fig.add_trace(&para;<br>            go.Histogram(&para;<br>                x=train[feature],&para;<br>                histnorm='probability'</ins><span>,&para;<br>          </span><ins style=\"background:#e6ffe6;\"> </ins><del style=\"background:#ffe6e6;\">\"n_estimators\":list(range(50,300,50))}&para;<br>random_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=5,scoring='roc_auc')&para;<br>random_search.fit(X_Train,y_Train)</del><ins style=\"background:#e6ffe6;\">     name=feature&para;<br>            ),            &para;<br>            row= r, col = c&para;<br>        )&para;<br>        i+=1&para;<br>&para;<br>fig.update_layout(height=2400, width=2100, title='Distributions of categorical variables')&para;<br>        &para;<br>fig.show()&para;<br></ins><span>\"\"\"</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">\"\"\"clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',random_state=42,class_weight='balanced',n_jobs=-1,verbose=1)&para;<br>params = {\"max_depth\":[3,4,5,6,-1],&para;<br>          \"learning_rate\":[0.01,0.05,0.1,0.3],&para;<br>          \"subsample\":[0.5,0.7,0.9],&para;<br>          \"colsample_bytree\":[0.5,0.7,0.9],&para;<br>          \"reg_alpha\":[0.5,1,2],&para;<br>          \"reg_lambda\":[0.5,1,2],&para;<br>          \"num_leaves\":[7,15,31,63],&para;<br>          \"n_estimators\":list(range(50,300,50))}&para;<br>random_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=5,scoring='roc_auc')&para;<br>random_search.fit(X_Train,y_Train)\"\"\"</del><ins style=\"background:#e6ffe6;\">remove_cols_transacton</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<del style=\"background:#ffe6e6;\">\"\"\"clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',random_state=42,class_weight='balanced',n_jobs=-1,verbose=1)&para;<br>params = {\"max_depth\":[3,4,5,6,-1],&para;<br>          \"learning_rate\":[0.01,0.05,0.1,0.3],&para;<br>          \"subsample\":[0.5,0.7,0.9],&para;<br>          \"colsample_bytree\":[0.5,0.7,0.9],&para;<br>          \"reg_alpha\":[0.5,1,2],&para;<br>          \"reg_lambda\":[0.5,1,2],&para;<br>          \"num_leaves\":[7,15,31,63],&para;<br>          \"n_estimators\":list(range(50,300,50))}&para;<br>random_search = RandomizedSearchCV(estimator=clf,param_distributions=params,cv=5,scoring='roc_auc')&para;<br>random_search.fit(X_Train,y_Train)\"\"\"</del><ins style=\"background:#e6ffe6;\">locs</ins>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_random(1,has_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18867817': [],\n",
       " '18868525': [],\n",
       " '20704078': [],\n",
       " '18870049': [],\n",
       " '20703998': [],\n",
       " '18868150': [<__main__.Cell at 0x7f616b974130>,\n",
       "  <__main__.Cell at 0x7f616b982d60>,\n",
       "  <__main__.Cell at 0x7f616b8e0e50>,\n",
       "  <__main__.Cell at 0x7f616b8fd250>,\n",
       "  <__main__.Cell at 0x7f616b8fd8b0>,\n",
       "  <__main__.Cell at 0x7f616b8db310>,\n",
       "  <__main__.Cell at 0x7f616b8db8e0>,\n",
       "  <__main__.Cell at 0x7f616b8dba30>,\n",
       "  <__main__.Cell at 0x7f616b8dbb80>,\n",
       "  <__main__.Cell at 0x7f616b8df1f0>,\n",
       "  <__main__.Cell at 0x7f616b894a60>,\n",
       "  <__main__.Cell at 0x7f616b89f5b0>,\n",
       "  <__main__.Cell at 0x7f616b89fb80>],\n",
       " '18868180': []}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kernel_trees.values())[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('RobustDataScience': conda)",
   "language": "python",
   "name": "python38264bitrobustdatasciencecondaff3daa7a14f54e6fb30e1fe30261bdb5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
